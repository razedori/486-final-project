{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load and prepare data\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('/Users/razedori/BYU/Stat 486/project movies/imdb.csv')\n",
    "df = df.dropna(subset=['Your Rating'])\n",
    "\n",
    "# Select features\n",
    "features = [\n",
    "    'Runtime (mins)',\n",
    "    'IMDb Rating',\n",
    "    'Year',\n",
    "    'Num Votes'\n",
    "]\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df['Your Rating'].copy()\n",
    "\n",
    "# 2. Basic preprocessing for PCA and clustering\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "X_processed = pd.DataFrame(\n",
    "    scaler.fit_transform(imputer.fit_transform(X)),\n",
    "    columns=X.columns\n",
    ")\n",
    "\n",
    "# 3. Apply PCA\n",
    "print(\"\\nApplying PCA...\")\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_processed)\n",
    "print(f\"Number of components selected by PCA: {pca.n_components_}\")\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "# 4. Perform clustering\n",
    "print(\"\\nPerforming cluster analysis...\")\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Visualize clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis')\n",
    "plt.title('Movie Clusters based on PCA')\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# 5. Nested CV function\n",
    "def perform_nested_cv(X, y, model, param_grid, name, outer_cv=3, inner_cv=2):\n",
    "    \"\"\"\n",
    "    Perform nested cross-validation with preprocessing pipeline\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    pipeline_param_grid = {f'model__{key}': value for key, value in param_grid.items()}\n",
    "    \n",
    "    outer_scores = []\n",
    "    outer_mse = []\n",
    "    cv_outer = KFold(n_splits=outer_cv, shuffle=True, random_state=42)\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(cv_outer.split(X), 1):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        cv_inner = KFold(n_splits=inner_cv, shuffle=True, random_state=42)\n",
    "        \n",
    "        search = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=pipeline_param_grid,\n",
    "            cv=cv_inner,\n",
    "            scoring='r2',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        search.fit(X_train, y_train)\n",
    "        predictions = search.predict(X_test)\n",
    "        \n",
    "        score = r2_score(y_test, predictions)\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        \n",
    "        outer_scores.append(score)\n",
    "        outer_mse.append(mse)\n",
    "        \n",
    "        print(f\"{name} - Fold {fold} Score: R² = {score:.3f}, MSE = {mse:.3f}\")\n",
    "    \n",
    "    print(f\"\\n{name} Final Results:\")\n",
    "    print(f\"Average R²: {np.mean(outer_scores):.3f} (±{np.std(outer_scores):.3f})\")\n",
    "    print(f\"Average MSE: {np.mean(outer_mse):.3f}\")\n",
    "    \n",
    "    return np.mean(outer_scores), np.mean(outer_mse)\n",
    "\n",
    "# 6. Define models and parameters\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10],\n",
    "        'min_samples_split': [2]\n",
    "    },\n",
    "    'Ridge': {\n",
    "        'alpha': [0.1, 1.0, 10.0]\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'alpha': [0.1, 1.0, 10.0]\n",
    "    },\n",
    "    'SVR': {\n",
    "        'C': [1.0, 10.0],\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42),\n",
    "    'SVR': SVR()\n",
    "}\n",
    "\n",
    "# 7. Perform nested CV\n",
    "print(\"\\nPerforming Nested Cross-Validation...\")\n",
    "nested_cv_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluating {name}...\")\n",
    "    avg_r2, avg_mse = perform_nested_cv(\n",
    "        X, y, model, param_grids[name], name\n",
    "    )\n",
    "    nested_cv_results[name] = {\n",
    "        'R2': avg_r2,\n",
    "        'MSE': avg_mse\n",
    "    }\n",
    "\n",
    "# 8. Train final Random Forest for SHAP analysis\n",
    "rf_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "rf_pipeline.fit(X, y)\n",
    "rf_model = rf_pipeline.named_steps['rf']\n",
    "\n",
    "# 9. SHAP Analysis\n",
    "print(\"\\nPerforming SHAP analysis...\")\n",
    "explainer = shap.TreeExplainer(rf_model)\n",
    "X_processed = rf_pipeline.named_steps['imputer'].transform(X)\n",
    "X_processed = rf_pipeline.named_steps['scaler'].transform(X_processed)\n",
    "X_processed = pd.DataFrame(X_processed, columns=X.columns)\n",
    "shap_values = explainer.shap_values(X_processed)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_processed, plot_type=\"bar\", show=False)\n",
    "plt.title(\"SHAP Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 10. Visualize model comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "model_names = list(nested_cv_results.keys())\n",
    "r2_scores = [results['R2'] for results in nested_cv_results.values()]\n",
    "\n",
    "plt.bar(model_names, r2_scores)\n",
    "plt.title('Model Performance Comparison (Nested CV)')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Average R² Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 11. Create prediction function\n",
    "def predict_movie_rating(runtime, imdb_rating, year, num_votes):\n",
    "    \"\"\"Predict rating for a new movie using only the Ridge model.\"\"\"\n",
    "    movie_features = pd.DataFrame({\n",
    "        'Runtime (mins)': [runtime],\n",
    "        'IMDb Rating': [imdb_rating],\n",
    "        'Year': [year],\n",
    "        'Num Votes': [num_votes]\n",
    "    })\n",
    "    \n",
    "    # Use the Ridge model\n",
    "    ridge_model = Ridge(random_state=42)\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', ridge_model)\n",
    "    ])\n",
    "    \n",
    "    # Train the Ridge model on the entire dataset\n",
    "    pipeline.fit(X, y)\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_rating = pipeline.predict(movie_features)[0]\n",
    "    print(f\"Predicted Rating (Ridge): {predicted_rating:.2f}\")\n",
    "    return predicted_rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multiple_movies(movies, model_choice='Ridge'):\n",
    "    \"\"\"\n",
    "    Predict ratings for multiple movies using the specified model.\n",
    "    \n",
    "    Parameters:\n",
    "        movies (list of dict): A list of dictionaries, each containing:\n",
    "            - 'Title': Title of the movie\n",
    "            - 'Runtime (mins)': Runtime of the movie in minutes\n",
    "            - 'IMDb Rating': IMDb rating of the movie\n",
    "            - 'Year': Release year of the movie\n",
    "            - 'Num Votes': Number of votes the movie received\n",
    "        model_choice (str): Model to use for prediction ('Ridge', 'Lasso', etc.)\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary with movie titles as keys and predicted ratings as values.\n",
    "    \"\"\"\n",
    "    # Check if the chosen model exists\n",
    "    if model_choice not in models:\n",
    "        raise ValueError(f\"Model '{model_choice}' not found. Choose from: {list(models.keys())}\")\n",
    "    \n",
    "    # Extract features from the movie data\n",
    "    movie_features = pd.DataFrame([\n",
    "        {\n",
    "            'Runtime (mins)': movie['Runtime (mins)'],\n",
    "            'IMDb Rating': movie['IMDb Rating'],\n",
    "            'Year': movie['Year'],\n",
    "            'Num Votes': movie['Num Votes']\n",
    "        }\n",
    "        for movie in movies\n",
    "    ])\n",
    "    \n",
    "    # Titles for differentiation\n",
    "    titles = [movie['Title'] for movie in movies]\n",
    "    \n",
    "    # Train the chosen model\n",
    "    model = models[model_choice]\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    pipeline.fit(X, y)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = pipeline.predict(movie_features)\n",
    "    \n",
    "    # Combine titles with predictions\n",
    "    results = {title: rating for title, rating in zip(titles, predictions)}\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movies = [\n",
    "    {\n",
    "        'Title': 'About Time',\n",
    "        'Runtime (mins)': 123,\n",
    "        'IMDb Rating': 7.4,\n",
    "        'Year': 2013,\n",
    "        'Num Votes': 4020000\n",
    "    },\n",
    "    {\n",
    "        'Title': 'The Lighthouse',\n",
    "        'Runtime (mins)': 149,\n",
    "        'IMDb Rating': 7.4,\n",
    "        'Year': 2019,\n",
    "        'Num Votes': 269000\n",
    "    },\n",
    "    {\n",
    "        'Title': 'The Substance',\n",
    "        'Runtime (mins)': 141,\n",
    "        'IMDb Rating': 7.4,\n",
    "        'Year': 2024,\n",
    "        'Num Votes': 161000\n",
    "    },\n",
    "     {\n",
    "        'Title': 'A nightmare on elm street',\n",
    "        'Runtime (mins)': 91,\n",
    "        'IMDb Rating': 7.4,\n",
    "        'Year': 1984,\n",
    "        'Num Votes': 213000\n",
    "    }\n",
    "]\n",
    "\n",
    "predicted_ratings = predict_multiple_movies(test_movies, model_choice='Ridge')\n",
    "\n",
    "print(\"Predicted Ratings:\")\n",
    "for title, rating in predicted_ratings.items():\n",
    "    print(f\"{title}: {rating:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
